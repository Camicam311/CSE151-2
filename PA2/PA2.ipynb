{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self,pure = False, subset = None,split_rule = None, \n",
    "                 yes = None,no = None, label = 0 ):\n",
    "        self.pure = pure\n",
    "        self.subset = subset\n",
    "        self.split_rule = split_rule\n",
    "        self.yes = yes\n",
    "        self.no = no\n",
    "        self.label = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = open(\"pa2features.txt\",\"r\")\n",
    "feature_name = [line.strip() for line in f1]\n",
    "\n",
    "f = open(\"pa2train.txt\",\"r\")\n",
    "train = [line.strip() for line in f]\n",
    "train = [[float(i) for i in line.split()] for line in train]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(features,index,threshold,amount):\n",
    "    z_0 = sum([z >= threshold for z,x in features[index]])\n",
    "    z_1 = amount - z_0\n",
    "    \n",
    "    pz0x0 = sum([z >= threshold and x == 0 for z,x in features[index]])/z_0\n",
    "    pz0x1 = 1-pz0x0\n",
    "    if (pz0x0 == 0 or pz0x1 == 0):\n",
    "        Hz_0 = 0\n",
    "    else:\n",
    "        Hz_0 = -pz0x0*np.log(pz0x0)-pz0x1*np.log(pz0x1)\n",
    "    \n",
    "    pz1x0 = sum([z <= threshold and x == 0 for z,x in features[index]])/z_1\n",
    "    pz1x1 = 1-pz1x0\n",
    "    if (pz1x0 == 0 or pz1x1 == 0):\n",
    "        Hz_1 = 0\n",
    "    else:\n",
    "        Hz_1 = -pz1x0*np.log(pz1x0)-pz1x1*np.log(pz1x1)\n",
    "    \n",
    "    return z_0/amount*Hz_0 + z_1/amount*Hz_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_entropy(subset):\n",
    "    features = [[(line[i],line[-1]) for line in subset] for i in range(22)]\n",
    "    features = [sorted(line) for line in features]\n",
    "    \n",
    "    thresholds = []\n",
    "    for i in range(22):\n",
    "        a = []\n",
    "        for j in range(1,len(subset)):\n",
    "            if features[i][j-1][0] < features[i][j][0]:\n",
    "                a += [(features[i][j-1][0]+features[i][j][0])/2]\n",
    "        thresholds += [a]\n",
    "    \n",
    "    entropy_l = []\n",
    "    for i in range(22):\n",
    "        for j in thresholds[i]:\n",
    "            entropy_l += [(entropy(features,i,j,len(subset)),i,j)]\n",
    "\n",
    "    return min(entropy_l)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build Decision Tree\n",
    "queue = []\n",
    "root = Node(subset = train)\n",
    "queue.append(root)\n",
    "\n",
    "while(len(queue) != 0 ):\n",
    "    node = queue.pop(0)\n",
    "    \n",
    "    node.split_rule = min_entropy(node.subset)\n",
    "    index,threshold = node.split_rule\n",
    "   \n",
    "    subset1 = [line for line in node.subset if line[index] < threshold]\n",
    "    node1 = Node(subset = subset1)\n",
    "        \n",
    "    if sum([line[-1] == 0 for line in subset1]) == 0:\n",
    "        node1.label = 1\n",
    "        node1.pure = True\n",
    "    elif sum([line[-1] == 1 for line in subset1]) == 0:\n",
    "        node1.label = 0\n",
    "        node1.pure = True\n",
    "    else:\n",
    "        queue.append(node1)\n",
    "    \n",
    "    subset2 = [line for line in node.subset if line[index] >= threshold]\n",
    "    node2 = Node(subset = subset2)\n",
    "    if sum([line[-1] == 0 for line in subset2]) == 0:\n",
    "        node2.label = 1\n",
    "        node2.pure = True\n",
    "    elif sum([line[-1] == 1 for line in subset2]) == 0:\n",
    "        node2.label = 0\n",
    "        node2.pure = True\n",
    "    else:\n",
    "        queue.append(node2)\n",
    "    \n",
    "    node.yes = node1\n",
    "    node.no = node2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level1:\n",
      "(4, 0.5) 2000\n"
     ]
    }
   ],
   "source": [
    "print(\"Level1:\")\n",
    "print(root.split_rule, len(root.subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level2:\n",
      "(0, 415000.0) 1319\n",
      "(4, 1.5) 681\n"
     ]
    }
   ],
   "source": [
    "print(\"Level2:\")\n",
    "print(root.yes.split_rule, len(root.yes.subset))\n",
    "print(root.no.split_rule, len(root.no.subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level3:\n",
      "(16, 2506.5) 1284\n",
      "(20, 208.0) 35\n",
      "(19, 584.5) 292\n",
      "(20, 2006.0) 389\n"
     ]
    }
   ],
   "source": [
    "print(\"Level3:\")\n",
    "print(root.yes.yes.split_rule, len(root.yes.yes.subset))\n",
    "print(root.yes.no.split_rule, len(root.yes.no.subset))\n",
    "print(root.no.yes.split_rule, len(root.no.yes.subset))\n",
    "print(root.no.no.split_rule, len(root.no.no.subset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First three levels decision tree are at the last page:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_test = open('pa2test.txt', 'r')\n",
    "test = [line.strip() for line in f_test]\n",
    "test = [[float(i) for i in line.split()] for line in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(root, item):\n",
    "    curr = root\n",
    "    while (not curr.pure):\n",
    "        index, threshold = curr.split_rule\n",
    "        if (item[index] < threshold):\n",
    "            curr = curr.yes\n",
    "        else: \n",
    "            curr = curr.no\n",
    "    return curr.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_error 0.0\n"
     ]
    }
   ],
   "source": [
    "train_result = [search(root,l) for l in train]\n",
    "train_error = sum([train_result[i] != train[i][-1] for i in range(len(train))])/len(train)\n",
    "print(\"train_error\", train_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_error 0.173\n"
     ]
    }
   ],
   "source": [
    "test_result = [search(root,l) for l in test]\n",
    "test_error = sum([test_result[i] != test[i][-1] for i in range(len(test))])/len(test)\n",
    "print(\"test_error\", test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_validate = open('pa2validation.txt', 'r')\n",
    "validate = [line.strip() for line in f_validate]\n",
    "validate = [[float(i) for i in line.split()] for line in validate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 validation_error 0.122\n",
      "test_error 0.117\n",
      "2 validation_error 0.107\n",
      "test_error 0.103\n"
     ]
    }
   ],
   "source": [
    "queue = []\n",
    "queue.append(root)\n",
    "i = 0\n",
    "while(not len(queue) == 0):\n",
    "    node = queue.pop(0)\n",
    "    validate_result = [search(root,l) for l in validate]\n",
    "    validate_error = sum([validate_result[i] != validate[i][-1] \n",
    "                          for i in range(len(validate))])/len(validate)\n",
    "    \n",
    "    if (node.pure):\n",
    "        continue\n",
    "    node.pure = True\n",
    "    node.label = sum([l[-1] == 1 for l in node.subset]) > sum([l[-1] == 0 for l in node.subset])\n",
    "    new_validate = [search(root,l) for l in validate]\n",
    "    new_error = sum([new_validate[i] != validate[i][-1] \n",
    "                          for i in range(len(validate))])/len(validate)\n",
    "    if new_error <= validate_error:\n",
    "        i += 1\n",
    "        print(i, \"validation_error\",new_error)\n",
    "        test_result = [search(root,l) for l in test]\n",
    "        test_error = sum([test_result[i] != test[i][-1] for i in range(len(test))])/len(test)\n",
    "        print(\"test_error\", test_error)\n",
    "    else:\n",
    "        node.pure = False\n",
    "        node.label = None\n",
    "        queue.append(node.yes)\n",
    "        queue.append(node.no)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PAYMENT_DELAY_SEPTEMBER'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_name[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PAYMENT_DELAY_SEPTEMBER is the most salient feature that predicts credit card default."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
