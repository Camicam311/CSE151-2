{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PA1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = open(\"pa1train.txt\", \"r\")\n",
    "pa1train = [line.strip() for line in f1]\n",
    "\n",
    "pa1train = [[int(i) for i in line.split()] for line in pa1train]\n",
    "train = [i[:784] for i in pa1train]\n",
    "train_label = [i[-1] for i in pa1train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2 = open(\"pa1validate.txt\",\"r\")\n",
    "pa1validate = [line.strip() for line in f2]\n",
    "pa1validate = [[int(i) for i in line.split()] for line in pa1validate]\n",
    "\n",
    "validate = [i[:784] for i in pa1validate]\n",
    "validate_label = [i[-1] for i in pa1validate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f3 = open(\"pa1test.txt\",\"r\")\n",
    "pa1test = [line.strip() for line in f3]\n",
    "pa1test = [[int(i) for i in line.split()] for line in pa1test]\n",
    "test = [i[:784] for i in pa1test]\n",
    "test_label = [i[-1] for i in pa1test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist(a,b):\n",
    "    return sum([(a[i]-b[i])**2 for i in range(len(a))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_dist(data1, training):\n",
    "    total = []\n",
    "    for i in range(len(data1)):\n",
    "        q = []\n",
    "        for j in range(len(training)):\n",
    "            q+=[(dist(data1[i],training[j]),j)]\n",
    "        total += [[l[1] for l in sorted(q)]]\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_total = total_dist(train,train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_total = total_dist(validate,train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_total = total_dist(test,train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def majority(list1):\n",
    "    dict1 = dict()\n",
    "    for i in list1:\n",
    "        if i not in dict1:\n",
    "            dict1[i] = 0\n",
    "        dict1[i] += 1\n",
    "    major =  [j for j in dict1 if dict1[j] == max([dict1[i] for i in dict1])]\n",
    "    return random.choice(major)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN(k):\n",
    "    inx = [[train_label[j] for j in l[:k]] for l in dist_total]\n",
    "    train_label_1 = [majority(l) for l in inx]\n",
    "    train_error = sum(train_label[i] != train_label_1[i] for i in range(len(train_label)))/len(train_label)\n",
    "    print(\"Training error:\",train_error)\n",
    "    \n",
    "    inx_valid = [[train_label[j] for j in l[:k]] for l in validate_total]\n",
    "    validate_label_1 = [majority(l) for l in inx_valid]\n",
    "    validate_error = sum(validate_label[i] != validate_label_1[i] for i in range(len(validate_label)))/len(validate_label)\n",
    "    print(\"Validation error:\",validate_error)\n",
    "\n",
    "    inx_test = [[train_label[j] for j in l[:k]] for l in test_total]\n",
    "    test_label_1 = [majority(l) for l in inx_test]\n",
    "    test_error = sum(test_label[i] != test_label_1[i] for i in range(len(test_label)))/len(test_label)\n",
    "    print(\"Test error:\",test_error)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error: 0.0\n",
      "Validation error: 0.082\n",
      "Test error: 0.094\n"
     ]
    }
   ],
   "source": [
    "KNN(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error: 0.055\n",
      "Validation error: 0.096\n",
      "Test error: 0.092\n"
     ]
    }
   ],
   "source": [
    "KNN(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error: 0.07\n",
      "Validation error: 0.109\n",
      "Test error: 0.102\n"
     ]
    }
   ],
   "source": [
    "KNN(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error: 0.093\n",
      "Validation error: 0.105\n",
      "Test error: 0.116\n"
     ]
    }
   ],
   "source": [
    "KNN(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error: 0.0425\n",
      "Validation error: 0.098\n",
      "Test error: 0.09\n"
     ]
    }
   ],
   "source": [
    "KNN(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:  The classifier of k=1 performs the best on validation data. \n",
    "\n",
    "Its test error is 0.094."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "f4 = open(\"projection.txt\", \"r\")\n",
    "projection = [line.strip() for line in f4]\n",
    "project = []\n",
    "for i in range(20):\n",
    "    p = []\n",
    "    for line in projection:\n",
    "        p += [float(line.split()[i])]\n",
    "    project += [p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot(list1,list2):\n",
    "    return sum([list1[i] * list2[i] for i in range(len(list1))])\n",
    "def add(list1,list2):\n",
    "    return [list1[i] + list2[i] for i in range(len(list1))]\n",
    "def mul(c, list1):\n",
    "    return [c*list1[i] for i in range(len(list1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Projection(matrix):\n",
    "    proj = []\n",
    "    for vec in matrix:\n",
    "        q = [0]*len(vec)\n",
    "        for i in project:\n",
    "            q = add(q, mul(dot(vec,i),i))\n",
    "        proj += [q]\n",
    "    return proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_proj = Projection(train)\n",
    "dist_total_proj = total_dist(train_proj,train_proj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_proj = Projection(validate)\n",
    "validation_total_proj = total_dist(validation_proj,train_proj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_proj = Projection(test)\n",
    "test_total_proj = total_dist(test_proj,train_proj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN_proj(k):\n",
    "    inx = [[train_label[j] for j in l[:k]] for l in dist_total_proj]\n",
    "    train_label_1 = [majority(l) for l in inx]\n",
    "    train_error = sum(train_label[i] != train_label_1[i] for i in range(len(train_label)))/len(train_label)\n",
    "    print(\"Training error:\",train_error)\n",
    "    \n",
    "    inx_valid = [[train_label[j] for j in l[:k]] for l in validation_total_proj]\n",
    "    validate_label_1 = [majority(l) for l in inx_valid]\n",
    "    validate_error = sum(validate_label[i] != validate_label_1[i] for i in range(len(validate_label)))/len(validate_label)\n",
    "    print(\"Validation error:\",validate_error)\n",
    "\n",
    "    inx_test = [[train_label[j] for j in l[:k]] for l in test_total_proj]\n",
    "    test_label_1 = [majority(l) for l in inx_test]\n",
    "    test_error = sum(test_label[i] != test_label_1[i] for i in range(len(test_label)))/len(test_label)\n",
    "    print(\"Test error:\",test_error)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error: 0.0\n",
      "Validation error: 0.32\n",
      "Test error: 0.314\n"
     ]
    }
   ],
   "source": [
    "KNN_proj(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error: 0.1905\n",
      "Validation error: 0.299\n",
      "Test error: 0.305\n"
     ]
    }
   ],
   "source": [
    "KNN_proj(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error: 0.2295\n",
      "Validation error: 0.297\n",
      "Test error: 0.285\n"
     ]
    }
   ],
   "source": [
    "KNN_proj(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error: 0.261\n",
      "Validation error: 0.295\n",
      "Test error: 0.297\n"
     ]
    }
   ],
   "source": [
    "KNN_proj(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error: 0.162\n",
      "Validation error: 0.314\n",
      "Test error: 0.3\n"
     ]
    }
   ],
   "source": [
    "KNN_proj(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:  The classifier of k=15 performs the best on validation data.\n",
    "\n",
    "Its test error is 0.297.\n",
    "\n",
    "After projection, the classification accuracy becomes less accurate.\n",
    "    \n",
    "The running becomes faster when run on projected data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
